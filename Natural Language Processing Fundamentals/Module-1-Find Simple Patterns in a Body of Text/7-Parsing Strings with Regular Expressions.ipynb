{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**\n",
    " \n",
    "Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries needed to complete the code Professor Melnikov presented in the video.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS\n",
    "IS.ast_node_interactivity = \"all\"    # allows multiple outputs from a cell\n",
    "import re, pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# Review\n",
    "\n",
    "Review the code Professor Melnikov used to parse strings with regexes in the previous video\n",
    "\n",
    "## Compare `re.findall()` and `re.split()`\n",
    "\n",
    "Previously we used [`re.findall()`](https://docs.python.org/3/library/re.html#re.findall) to find pattern matching words. This can be generalized to find all words in a sentence. Essentially, this is parsing a sentence into word tokens. Alternatively, we can use [`re.split()`](https://docs.python.org/3/library/re.html#re.split) to split string on the `\\W+` regex pattern to find all word tokens. It splits the string on any non-word characters, meaning anything that isn't a letter, digit, or underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy_dog']\n",
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy_dog', '']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sFox = 'The quick-brown fox jumps over the lazy_dog...'\n",
    "print(re.findall('\\w+', sFox))     # split on at least one contiguous word character\n",
    "print(re.split('\\W+', sFox))       # split on at least one contiguous non-word character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the extra empty string found by `re.split()`. Non-word characters such as `'...'` at the end of the string `s` separate `'lazy_dog'` from the empty string `''`. There are many ways to fix this, but the key takeaway is to always evaluate your results after applying any string processing method and note any unusual behavior.\n",
    "\n",
    "You could also tokenize a sentence into words with a [character class](https://www.regular-expressions.info/charclass.html), defined by square brackets `[]`, to find words between spaces and punctuation. For this method to be successful, the character class needs to list all word-separating characters in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'is', 'gr8', 'Python-3', 'is', 'A1']\n",
      "['NLP', 'is', 'gr8', 'Python-3', 'is', 'A1', '']\n"
     ]
    }
   ],
   "source": [
    "s = 'NLP is gr8! Python-3 is A1.'\n",
    "print(re.findall('[^ !.]+', s))  # split on at least one contiguous character other than space, ! or a period\n",
    "print(re.split('[ !.]+', s))     # split on at last one contiguous space or ! or a period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, just space (` `), `!`, and `.` are sufficient to identify words. \n",
    "\n",
    "## Parsing Words that Contain Periods\n",
    "\n",
    "If some of the words in your document include periods, forcing a period+space combination may be necessary so words that contain periods aren't split. The word pattern `'. '` is often used to separate sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP is gr8', ' Python-3', 'x is A1']\n",
      "['NLP is gr8', ' Python-3', 'x is A1', '']\n",
      "['NLP is gr8', 'Python-3.x is A1.']\n"
     ]
    }
   ],
   "source": [
    "s = 'NLP is gr8! Python-3.x is A1.'\n",
    "print(re.findall('[\\w -]+', s))   # split on at least one contiguous word character r space or -\n",
    "print(re.split('[.!?]+', s))      # split on at least one period or ! or ?\n",
    "print(re.split('[.!?] +', s))     # split on a single character in character class followed by a space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, be cautious because some sentences may lack a period or a space. For example, menu items in Wikipedia article are period-less, yet still can be considered as sentences or independent phrases, so they would need individual processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# Optional Practice\n",
    "\n",
    "Let's continue with a bit of practice of our own. \n",
    "\n",
    "Start with the [presidential oath](https://constitution.congress.gov/browse/essay/artII-S1-C8-1/ALDE_00001126/), which we will parse into individual words and sentences.\n",
    "\n",
    "As you work through these tasks, check your answers by running your code in the *#check solution here* cell, to see if you’ve gotten the correct result. If you get stuck on a task, click the See **solution** drop-down to view the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article II, Section 1, Clause 8:\n",
      "\n",
      "Before he enter on the Execution of his Office, he shall take the following Oath or Affirmation:\n",
      "–I do solemnly swear (or affirm) that I will faithfully execute the Office of President of the United States, and will to the best of my Ability, preserve, protect and defend the Constitution of the United States.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Article II, Section 1, Clause 8:\\n\\nBefore he enter on the Execution of his Office, he shall take the following Oath or Affirmation:\\n–I do solemnly swear (or affirm) that I will faithfully execute the Office of President of the United States, and will to the best of my Ability, preserve, protect and defend the Constitution of the United States.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sOath = 'Article II, Section 1, Clause 8:\\n\\n\\\n",
    "Before he enter on the Execution of his Office, he shall take the following Oath or Affirmation:\\n\\\n",
    "–I do solemnly swear (or affirm) that I will faithfully execute \\\n",
    "the Office of President of the United States, and will to the best of my Ability, \\\n",
    "preserve, protect and defend the Constitution of the United States.'\n",
    "print(sOath)\n",
    "sOath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Split oath at the colon character and return a list of 3 individual sentences.\n",
    "\n",
    " <b>Hint:</b> Try splitting on <code>':'</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#b31b1>▶</font>\n",
    "            See <b>solution</b>.</summary>\n",
    "            <pre>\n",
    "re.split(':', sOath)     # solution 1: split oath at the colon character\n",
    "re.split(r':+', sOath)   # solution 2: split oath at the colon character\n",
    "            </pre>\n",
    "        </details>\n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 \n",
    "\n",
    "Parse oath into word tokens (which consist of any number of word characters) and return their count. \n",
    "\n",
    "<b>Hint:</b> Try finding all contiguous <code>'\\w'</code> characters, which will essentially split on non-word characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#b31b1>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "len(re.findall('\\w+', sOath)) # find number of words in sOath\n",
    "            </pre>\n",
    "        </details>\n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Split oath into individual words again, but this time identify the longest word and its count. \n",
    "\n",
    "<b>Hint:</b> Parse as you did above. Then compute lengths and use <code>sorted()</code> or <code>max()</code> methods to find the longest word. You can also use a Pandas DataFrame to accomplish these tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#b31b1>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "# find longest word and its length (in characters)\n",
    "LsWords = re.findall('\\w+', sOath)\n",
    "\n",
    "sorted([(w, len(w)) for w in LsWords], key=lambda w_len: w_len[1], reverse=True)  # solution 1\n",
    "\n",
    "max([(w, len(w)) for w in LsWords], key=lambda w_len: w_len[1])  # solution 2; ?max to view help\n",
    "\n",
    "df = pd.DataFrame(LsWords, columns=['word'])\n",
    "df['Len'] = df.word.str.len()\n",
    "df.sort_values('Len').tail(1).values.ravel().tolist()      # solution 3\n",
    "\n",
    "df.iloc[df.Len.idxmax(1)].values.tolist()                  # solution 4\n",
    "\n",
    "ls = re.findall('\\w+', sOath)                              # solution 5\n",
    "res = [len(i) for i in ls]\n",
    "ls[res.index(max(res))], max(res)\n",
    "            </pre>\n",
    "        </details>\n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Find all non-overlapping neighboring word pairs (i.e., 2-grams) separated by a space, where a word is a sequence of word characters, `\\w`, between non-word characters, `\\W`, or string start/end.\n",
    "\n",
    "So, `'Article II'` qualifies because `'Article'` and `'II'` are space-separated words, but the 2-gram `'II, Section'` does not because these words are separated by `', '` and not by a space. \n",
    "\n",
    "<b>Hint:</b> Try using a regex string with two <code>'\\w+'</code> search patterns with a space in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#b31b1>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "# find word pairs separated by a space\n",
    "re.findall('\\w+ \\w+', sOath)\n",
    "            </pre>\n",
    "        </details>\n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "\n",
    "Find all space-separated word pairs again (as in Task 4) with the first word starting with the letter `'o'` and the second word starting with the letter `'t'` or `'o'`. Ignore letter casing.\n",
    "\n",
    "<b>Hint:</b> Same as above, but you need to add starting letters to the pattern and word boundaries to ensure only one starting letter is considered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#b31b1>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "# find all case-ignorant space-separated word pairs, \n",
    "# where first word starts with 'o' and second word starts with 't'\n",
    "# Solution 1 with double escape characters (without raw string)\n",
    "re.findall('\\\\bo\\\\w+ \\\\b[ot]\\\\w+', sOath, flags=re.IGNORECASE)\n",
    "#\n",
    "# Solution 2 with raw string. Recall (from the *Practice Parsing Strings with Regular Expressions* in the first Jupyter Notebook (JN)  that `r'...'` is a raw string which cancels the effect of the escape character `\\`.\n",
    "re.findall(r'\\bo\\w+ \\b[ot]\\w+', sOath, flags=re.IGNORECASE)\n",
    "            </pre>\n",
    "        </details>\n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "\n",
    "Find all space-separated word pairs again, this time with the first word being one character long. Ignore letter casing.\n",
    "\n",
    "<b>Hint:</b> You can use a single word character search to find one-letter words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#b31b1>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "# find all case-ignorant space-separated word pairs, where first word has a single letter\n",
    "re.findall(r'\\b\\w \\b\\w+', sOath, flags=re.IGNORECASE)\n",
    "            </pre>\n",
    "        </details>\n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Lists\n",
    "\n",
    "\n",
    "In this example we will apply a parsing method to a list of email addresses. Parsing lists containing semi-structured elements is a common task. Such lists can contain addresses (email, home, IP), numeric identifiers (phone numbers, student IDs, social security numbers), login names (SkypeID, Facebook ID), or even short messages (tweets, reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sClass = '\\\n",
    "<Alex> KeepOnLearning@eCornell.com; \\\n",
    "<Anna> LifeLongLearner@outlook.com; \\\n",
    "<Atya> Student777@gmail.com; \\\n",
    "<Alice> ScienceGr8@Cornell.edu; '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "\n",
    "Return a list of 4 students (names and emails), i.e., parse the list at characters separating the students' information.\n",
    "\n",
    "<b>Hint:</b> Try splitting on <code>'; '</code>. You might need to remove one empty string element from the resulting list to return student names/emails only. In a bit more advanced solution you can remove the angle brackets also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details><summary><font color=#b31b1>▶</font>See <b>solution</b>.</summary>\n",
    "            <pre>\n",
    "# your solution goes here\n",
    "LsStud = re.split('; ', sClass)[:-1]  # return a list of 4 students\n",
    "#--- Drop brackets in student names\n",
    "[s.replace('<','').replace('>', '') for s in LsStud] # solution 1\n",
    "[re.sub('[<>]','', s) for s in LsStud] # solution 2 via ReGex's sub\n",
    "            </pre>\n",
    "        </details>\n",
    "</font>\n",
    "        \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8\n",
    "\n",
    "Return a list of valid email addresses only.\n",
    "\n",
    "<b>Hint:</b> Use a cominbation of word boundary, word characters, <code>'@'</code> symbol, and an escaped period character to construct the search pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#b31b1b>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "re.findall(r'\\b\\w+@\\w+\\.\\w+', sClass)  # return list of email addresses\n",
    "            </pre>\n",
    "        </details>\n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9\n",
    "\n",
    "Return a list of valid lower-cased email domains, such as `'Cornell.edu'`.\n",
    "\n",
    "<b>Hint:</b> Similar to above, but your search pattern starts with characters following the @ symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#b31b1>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "re.findall(r'\\b\\w+\\.\\w+', sClass.lower())  # return list of email domain names. E.g. \"gmail.com\"\n",
    "            </pre>\n",
    "        </details>\n",
    "</font>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
