{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part One of the Course Project\n",
    "\n",
    "In this part of the course project, you will write code to complete function to split strings in a particular way, using the `split()` methods from both the standard Python library and the `re` library. As you determine how to best complete each function, carefully consider whether to use built-in string methods or regex methods. \n",
    "\n",
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**\n",
    " \n",
    "Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries needed to complete this part of the course project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "edde97fe5458eff2505205c2a65c216d",
     "grade": false,
     "grade_id": "cell-f541125af77314e9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice's Adventures in Wonderland by Lewis Carroll 1865]\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import nltk, re\n",
    "from collections import Counter\n",
    "import numpy.testing as npt, unittest\n",
    "from typing import List\n",
    "from colorunittest import run_unittest\n",
    "eq, aeq = npt.assert_equal, npt.assert_almost_equal\n",
    "tmp = nltk.download(['gutenberg'], quiet=True)        # See https://www.nltk.org/book/ch02.html\n",
    "sRAW = nltk.corpus.gutenberg.raw('carroll-alice.txt') # string Raw Alice in Wonderland\n",
    "sRAW[:200]\n",
    "print(sRAW[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "839444be98e765fec2eb7f3bdd773994",
     "grade": true,
     "grade_id": "func_definitions",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Student: do not delete or modify this cell. It is used by autograder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# **Your Tasks**\n",
    "\n",
    "There are 6 tasks for you to complete below.   \n",
    "\n",
    "## Checking Your Work\n",
    "\n",
    "Test cases are provided below the code cell associated with each task. \n",
    "\n",
    "## **Task 1**\n",
    "\n",
    "Complete the `ParseOnWS()` function so that it:  \n",
    "- splits a string document by **whitespace** characters, i.e., ` `&nbsp;(space), `\\t` (tab), `\\n` (newline), `\\r` (carriage return), into a list of string tokens. \n",
    "- if specified, lowercases the string before tokenizing it so the returned list of string tokens is lowercased.\n",
    "\n",
    "For reference, review these pages in the course:\n",
    "- Preprocess Substrings with Operations\n",
    "- Practice Preprocessing Substrings with Operations\n",
    "- String Manipulation Methods (downloadable Tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e101d8024f05bdea76f1632c7fc8c095",
     "grade": false,
     "grade_id": "ParseOnWS_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CELL\n",
    "def ParseOnWS(sDoc='Cats and dogs!', LCase=False)->List[str]:\n",
    "    ''' Parse a string document on WHITESPACE using its split() method.\n",
    "    sDoc (str): a document, which needs to be tokenized.\n",
    "    LCase (bool): whether sDoc needs to be lower-cased before tokenization.\n",
    "    Returns a list of string tokens from sDoc.\n",
    "    Note: Newline characters (\\n) should not generate list elements.'''\n",
    "    # YOUR CODE HERE\n",
    "    if LCase:\n",
    "        sDoc = sDoc.lower()\n",
    "    return sDoc.split()\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03a0f5172c870ebb22bfe728fdbb3eeb",
     "grade": true,
     "grade_id": "ParseOnWS_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran 6 tests in 0.008s\n",
      "\n",
      "\u001b[1m\u001b[34mOK\u001b[0m\n",
      "test_00 (__main__.TestParseOnWS) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_01 (__main__.TestParseOnWS) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_02 (__main__.TestParseOnWS) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_03 (__main__.TestParseOnWS) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_04 (__main__.TestParseOnWS) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_05 (__main__.TestParseOnWS) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "@run_unittest\n",
    "class TestParseOnWS(unittest.TestCase):\n",
    "    def test_00(self): eq(ParseOnWS(), ['Cats','and','dogs!'])\n",
    "    def test_01(self): eq(ParseOnWS(LCase=True), ['cats','and','dogs!'])\n",
    "    def test_02(self): eq(ParseOnWS('a\\t \\t\\tb\\nc\\rd e !!'), ['a', 'b', 'c', 'd', 'e', '!!'])\n",
    "    def test_03(self): eq(ParseOnWS(sRAW)[:5], [\"[Alice's\", 'Adventures', 'in', 'Wonderland', 'by'])\n",
    "    def test_04(self): eq(ParseOnWS(sRAW, True)[:5], [\"[alice's\", 'adventures', 'in', 'wonderland', 'by'])\n",
    "    def test_05(self): eq(len(ParseOnWS('My dog has fleas.\\n')),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 2**\n",
    "\n",
    "Complete the `ParseOnSP()` function so that it splits a `string` document into a list of string tokens on the **space** character ` `.\n",
    "\n",
    "For reference, review these pages in the course:\n",
    "- Preprocess Substrings with Operations\n",
    "- Practice Preprocessing Substrings with Operations\n",
    "- String Manipulation Methods (downloadable Tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4716bc2a59c947bbd6424ead81184193",
     "grade": false,
     "grade_id": "ParseOnSP_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CELL\n",
    "def ParseOnSP(sDoc='Cats and dogs!', LCase=False)->List[str]:\n",
    "    ''' Parse a string document on SPACE using its split() method.\n",
    "    sDoc (str): a document, which needs to be tokenized.\n",
    "    LCase (bool): whether sDoc needs to be lower-cased before tokenization.\n",
    "    Returns a list of string tokens from sDoc.'''\n",
    "    # YOUR CODE HERE\n",
    "    if LCase:\n",
    "        sDoc = sDoc.lower()\n",
    "    return sDoc.split(' ')\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de17f953c37d1717b069ee649182b5ac",
     "grade": true,
     "grade_id": "ParseOnSP_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran 5 tests in 0.007s\n",
      "\n",
      "\u001b[1m\u001b[34mOK\u001b[0m\n",
      "test_00 (__main__.TestParseOnSP) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_01 (__main__.TestParseOnSP) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_02 (__main__.TestParseOnSP) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_03 (__main__.TestParseOnSP) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_04 (__main__.TestParseOnSP) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "@run_unittest\n",
    "class TestParseOnSP(unittest.TestCase):\n",
    "    def test_00(self): eq(ParseOnSP(), ['Cats','and','dogs!'])\n",
    "    def test_01(self): eq(ParseOnSP(LCase=True), ['cats','and','dogs!'])\n",
    "    def test_02(self): eq(ParseOnSP('a\\t \\t\\tb\\nc\\rd e  !!'), ['a\\t', '\\t\\tb\\nc\\rd', 'e', '', '!!'])\n",
    "    def test_03(self): eq(ParseOnSP(sRAW)[:5], [\"[Alice's\", 'Adventures', 'in', 'Wonderland', 'by'])\n",
    "    def test_04(self): eq(ParseOnSP(sRAW, True)[:5], [\"[alice's\", 'adventures', 'in', 'wonderland', 'by'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 3**\n",
    "\n",
    "Complete the `ParseOnRE()` function so it splits a string document into a list of string tokens by the `[\\s.!?:;\"]` character class. Use the `re.split()` method and allow at least one repeat. \n",
    "\n",
    "For reference, review these pages in the course:\n",
    "- Parsing Strings with Regular Expressions\n",
    "- Practice Parsing Strings with Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab175fc63d5095f98d64b082d137906a",
     "grade": false,
     "grade_id": "ParseOnRE_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CELL\n",
    "def ParseOnRE(sDoc='Cats and dogs!', LCase=False) -> List[str]:\n",
    "    ''' Parse a string document on [\\s.!?:;\"] character class using re.split().\n",
    "    sDoc (str):   a document, which needs to be tokenized.\n",
    "    LCase (bool): whether sDoc needs to be lower-cased before tokenization.\n",
    "    Returns a list of string tokens from sDoc'''\n",
    "    # YOUR CODE HERE\n",
    "    if LCase:\n",
    "        sDoc = sDoc.lower()\n",
    "    return re.split(r'[\\s.!?:;\"]+', sDoc)\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb294c594e92f39e24a38645c081486a",
     "grade": true,
     "grade_id": "ParseOnRE_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran 5 tests in 0.027s\n",
      "\n",
      "\u001b[1m\u001b[34mOK\u001b[0m\n",
      "test_00 (__main__.TestParseOnRE) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_01 (__main__.TestParseOnRE) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_02 (__main__.TestParseOnRE) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_03 (__main__.TestParseOnRE) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_04 (__main__.TestParseOnRE) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "@run_unittest\n",
    "class TestParseOnRE(unittest.TestCase):\n",
    "    def test_00(self): eq(ParseOnRE(), ['Cats', 'and', 'dogs', ''])\n",
    "    def test_01(self): eq(ParseOnRE(LCase=True), ['cats', 'and', 'dogs', ''])\n",
    "    def test_02(self): eq(ParseOnRE('a\\t \\t\\tb\\nc\\rd e  !!'), ['a', 'b', 'c', 'd', 'e', ''])\n",
    "    def test_03(self): eq(ParseOnRE(sRAW)[:5], [\"[Alice's\", 'Adventures', 'in', 'Wonderland', 'by'])\n",
    "    def test_04(self): eq(ParseOnRE(sRAW, True)[:5], [\"[alice's\", 'adventures', 'in', 'wonderland', 'by'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 4**\n",
    "\n",
    "Complete the `GetWords()` function so that it takes a string document and returns a list of string tokens extracted with a word character, `\\w`. Use `re.findall()` function and allow at least one repeat. \n",
    "\n",
    "For reference, review these pages in the course:\n",
    "- Use Regular Expressions to Find Patterns\n",
    "- Practice Using Regular Expressions to Find Patterns\n",
    "- Parsing Strings with Regular Expressions\n",
    "- Practice Parsing Strings with Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6693697a7c76b42c049c25e72700088e",
     "grade": false,
     "grade_id": "GetWords_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CELL\n",
    "def GetWords(sDoc:str='Cats and dogs!', LCase=False)->List[str]:\n",
    "    ''' Parse a string document to extract words using re.findall() and repeated \\w pattern.\n",
    "    sDoc (str): a document, which needs to be tokenized.\n",
    "    LCase (bool): whether sDoc needs to be lower-cased before tokenization.\n",
    "    Returns a list of tokens from sDoc'''\n",
    "    # YOUR CODE HERE\n",
    "    if LCase:\n",
    "        sDoc = sDoc.lower()\n",
    "    return re.findall(r'\\w+', sDoc)\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42f247da64acbf976050568729dde138",
     "grade": true,
     "grade_id": "GetWords_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran 5 tests in 0.023s\n",
      "\n",
      "\u001b[1m\u001b[34mOK\u001b[0m\n",
      "test_00 (__main__.TestGetWords) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_01 (__main__.TestGetWords) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_02 (__main__.TestGetWords) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_03 (__main__.TestGetWords) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_04 (__main__.TestGetWords) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "@run_unittest\n",
    "class TestGetWords(unittest.TestCase):\n",
    "    def test_00(self): eq(GetWords(), ['Cats','and','dogs'])\n",
    "    def test_01(self): eq(GetWords(LCase=True), ['cats','and','dogs'])\n",
    "    def test_02(self): eq(GetWords('a\\t \\t\\tb\\nc\\rd e  !!'), ['a', 'b', 'c', 'd', 'e'])\n",
    "    def test_03(self): eq(GetWords(sRAW)[:5], ['Alice', 's', 'Adventures', 'in', 'Wonderland'])\n",
    "    def test_04(self): eq(GetWords(sRAW, True)[:5], ['alice', 's', 'adventures', 'in', 'wonderland'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 5**\n",
    "\n",
    "Complete the `GetLex` function so that it retrieves an alphabetically sorted list of unique tokens from the a string document. Use `GetWords()` to tokenize the document.\n",
    "\n",
    "For an example of sorting and an example of returning unique items, refer to the three practice tasks in the notebook on this page, found in Module 2:\n",
    "- Parsing a Document into Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2433544252e0577448ae2a9dc8d294fc",
     "grade": false,
     "grade_id": "GetLex_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CELL\n",
    "def GetLex(sDoc:str='S t a t i s t i c s ', LCase=False)->int:\n",
    "    ''' Parse a string document with GetWords(), remove duplicates and order alphabetically.\n",
    "    sDoc (str): a document, which needs to be tokenized.\n",
    "    LCase (bool): whether sDoc needs to be lower-cased before tokenization.\n",
    "    Returns a list of ordered unique words from sDoc'''\n",
    "    # YOUR CODE HERE\n",
    "    words = GetWords(sDoc)\n",
    "    if LCase:\n",
    "        words = [word.lower() for word in words]\n",
    "    unique_sorted_words = sorted(set(words))\n",
    "    return unique_sorted_words\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d6b2210c05a061fa9253b03d95b063b",
     "grade": true,
     "grade_id": "GetLex_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran 6 tests in 0.003s\n",
      "\n",
      "\u001b[1m\u001b[34mOK\u001b[0m\n",
      "test_00 (__main__.TestGetLex) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_01 (__main__.TestGetLex) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_02 (__main__.TestGetLex) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_03 (__main__.TestGetLex) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_04 (__main__.TestGetLex) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_05 (__main__.TestGetLex) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "sPoem = '\"Rage, rage against the dying of the light.\" -- Dylan Thomas'\n",
    "@run_unittest\n",
    "class TestGetLex(unittest.TestCase):\n",
    "    def test_00(self): eq(GetLex(), ['S', 'a', 'c', 'i', 's', 't'])   # unique characters\n",
    "    def test_01(self): eq(GetLex(LCase=True), ['a', 'c', 'i', 's', 't'])\n",
    "    def test_02(self): eq(GetLex(sPoem), ['Dylan', 'Rage', 'Thomas', 'against', 'dying', 'light', 'of', 'rage', 'the'])\n",
    "    def test_03(self): eq(GetLex(sPoem, True), ['against', 'dying', 'dylan', 'light', 'of', 'rage', 'the', 'thomas'])\n",
    "    def test_04(self): eq(GetLex(sRAW[:50]), ['Adventures', 'Alice', 'Carroll', 'Lewis', 'Wonderland', 'by', 'in', 's'])\n",
    "    def test_05(self): eq(GetLex(sRAW[:50], True), ['adventures', 'alice', 'by', 'carroll', 'in', 'lewis', 's', 'wonderland'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 6**\n",
    "\n",
    "Complete the `GetTokFreq()` function so that it returns a list of counts in decreasing-order, from the most frequent words to the least frequent words in a string document. Use `GetWords()` to tokenize the document.\n",
    "\n",
    "For reference, review these pages in the course:\n",
    "- Count Substrings\n",
    "- Practice Counting Substrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1798102fd46736ff472132c27371cb8",
     "grade": false,
     "grade_id": "GetTokFreq_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CELL\n",
    "def GetTokFreq(sDoc:str='S t a t i s t i c s ', LCase=False, n=20)->List[int]:\n",
    "    ''' Parse sDoc with GetWords() and compute word frequencies using collections.Counter().\n",
    "    sDoc (str): a document, which needs to be tokenized.\n",
    "    LCase (bool): whether sDoc needs to be lower-cased before tokenization.\n",
    "    Returns a list of decreasing counts for top n most frequent words in sDoc'''\n",
    "    # YOUR CODE HERE\n",
    "    words = GetWords(sDoc)\n",
    "    if LCase:\n",
    "        words = [word.lower() for word in words]\n",
    "    word_counts = Counter(words)\n",
    "    most_common_counts = [count for word, count in word_counts.most_common(n)]\n",
    "    return most_common_counts\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9da9718ba44ab56478146dbbd37e7084",
     "grade": true,
     "grade_id": "GetTokFreq_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran 5 tests in 0.003s\n",
      "\n",
      "\u001b[1m\u001b[34mOK\u001b[0m\n",
      "test_00 (__main__.TestGetTokFreq) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_01 (__main__.TestGetTokFreq) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_02 (__main__.TestGetTokFreq) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_03 (__main__.TestGetTokFreq) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "test_04 (__main__.TestGetTokFreq) ... \u001b[1m\u001b[34mok\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "sPoem = '\"Rage, rage against the dying of the light.\" -- Dylan Thomas'\n",
    "@run_unittest\n",
    "class TestGetTokFreq(unittest.TestCase):\n",
    "    def test_00(self): eq(GetTokFreq(), [3, 2, 2, 1, 1, 1])   # most frequent characters\n",
    "    def test_01(self): eq(GetTokFreq(LCase=True), [3, 3, 2, 1, 1])\n",
    "    def test_02(self): eq(GetTokFreq(sPoem), [2, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "    def test_03(self): eq(GetTokFreq(sPoem, True), [2, 2, 1, 1, 1, 1, 1, 1])\n",
    "    def test_04(self): eq(GetTokFreq(sRAW[:50]), [1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
