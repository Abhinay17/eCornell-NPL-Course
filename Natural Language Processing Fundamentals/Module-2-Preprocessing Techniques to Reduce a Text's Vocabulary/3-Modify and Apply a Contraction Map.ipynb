{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**\n",
    " \n",
    "Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries needed to complete the code Professor Melnikov presented in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "!pip -q install contractions > tmp   # install contractions package\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS\n",
    "IS.ast_node_interactivity = \"all\"    # allows multiple outputs from a cell\n",
    "import nltk, re, pandas as pd, contractions\n",
    "_ = nltk.download(['gutenberg'], quiet=True)\n",
    "sAlice = nltk.corpus.gutenberg.raw(fileids='carroll-alice.txt').lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# **Review**\n",
    "\n",
    "Contractions make speaking a language easier, but they increase the size of the vocabulary in your document without adding any information, so it is best to expand them into their uncontracted form as a part of preprocessing. Here, you'll review three types of rules you can use to expand contractions. \n",
    "\n",
    "## Generic Rules\n",
    "\n",
    "\n",
    "A generic contraction expansion rule focuses on the [clitic](https://en.wikipedia.org/wiki/Clitic), i.e., the characters representing the second word in the contraction. For example, the `'m` postfix in `I'm` is a clitic. The advantage is that with a few generic rules, we can expand most contractions. Here, you'll create a function that applies regex substitution to several clitics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unContract_generic(sTxt='') -> str:\n",
    "    '''Search and replace generic contraction forms.\n",
    "    Input: \n",
    "        sTxt: input string with contractions\n",
    "    Returns:\n",
    "        string with expanded contractions   '''\n",
    "    # substitute pattern of a string sTxt with expansion replacement\n",
    "    sTxt = re.sub(r\"n\\'t\", \" not\", sTxt)\n",
    "    sTxt = re.sub(r\"\\'re\", \" are\", sTxt)\n",
    "    sTxt = re.sub(r\"\\'s\", \" is\", sTxt)\n",
    "    sTxt = re.sub(r\"\\'d\", \" would\", sTxt)\n",
    "    sTxt = re.sub(r\"\\'ll\", \" will\", sTxt)\n",
    "    sTxt = re.sub(r\"\\'t\", \" not\", sTxt)\n",
    "    sTxt = re.sub(r\"\\'ve\", \" have\", sTxt)\n",
    "    sTxt = re.sub(r\"\\'m\", \" am\", sTxt)\n",
    "    return sTxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this function to a simple phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is the time when NLP is booming.\n"
     ]
    }
   ],
   "source": [
    "sTxt = \"Now's the time when NLP's booming.\"\n",
    "print(unContract_generic(sTxt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function worked well in this example. Most contractions can be expanded using a few generic rules, but it can be risky to use these rules broadly. A clitic `'s` can be expanded into multiple variants, such as `was`, `is`, `has`. It can also mean a plural form for some words, such as `A's and B's`, and a [possessive](https://en.wikipedia.org/wiki/Possessive) form of a word, such as `no man's land`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are welcome in Ed is kitchen\n"
     ]
    }
   ],
   "source": [
    "sTxt = \"You're welcome in Ed's kitchen\"\n",
    "print(unContract_generic(sTxt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black\"> The function incorrectly expanded `Ed's` kitchen, because the  `'s` is a possessive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Rules\n",
    "\n",
    "To lessen the risk of incorrectly expanding contractions with a generic rule, you can develop a specific set of rules for contraction expansion. To search a string for all contractions in a single pass, you can first package them in a dictionary as key-value pairs, where the key is contraction and its value is the expansion. Then, you can use regex to compile a single search string of all keys. This approach is more computationally efficient than a multi-pass search through the string, especially for very large corpora. \n",
    "    \n",
    "`ContractionsMap` is a dictionary with several specific rules. Note that this set of contractions is still too small to express all possible contractions, since there are at least as many of them as there are nouns in the English language. However, this set covers most commonly observed cases. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ContractionsMap = { \n",
    "    \"ain't\": \"am not\", # / are not / is not / has not / have not\",\n",
    "    \"aren't\": \"are not\", # / am not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he had\", # / he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he shall\", # / he will\",\n",
    "    \"he'll've\": \"he shall have\", # / he will have\",\n",
    "    \"he's\": \"he has\", # / he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how has\", # / how is / how does\",\n",
    "    \"I'd\": \"I had\", # / I would\",\n",
    "    \"I'd've\": \"I would have\",\n",
    "    \"I'll\": \"I shall\", # / I will\",\n",
    "    \"I'll've\": \"I shall have\", # / I will have\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it had\", # / it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it shall\", # / it will\",\n",
    "    \"it'll've\": \"it shall have\", # / it will have\",\n",
    "    \"it's\": \"it has\", # / it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she had\", # / she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she shall\", # / she will\",\n",
    "    \"she'll've\": \"she shall have:, # / she will have\",\n",
    "    \"she's\": \"she has\", # / she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\", # / so is\",\n",
    "    \"that'd\": \"that would\", # / that had\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that has\", # / that is\",\n",
    "    \"there'd\": \"there had\", # / there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there has\", # / there is\",\n",
    "    \"they'd\": \"they had\", # / they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they shall\", # / they will\",\n",
    "    \"they'll've\": \"they shall have\", # / they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we had\", # / we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what shall\", # / what will\",\n",
    "    \"what'll've\": \"what shall have\", # / what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what has\", # / what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when has\", # / when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where has\", # / where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who shall\", # / who will\",\n",
    "    \"who'll've\": \"who shall have\", # / who will have\",\n",
    "    \"who's\": \"who has\", # / who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why has\", # / why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you had\", # / you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you shall\", # / you will\",\n",
    "    \"you'll've\": \"you shall have\", # / you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile a regex search of contraction keys from `ContractionsMap` and replace the match with the corresponding expansion. The trick is to combine all keys containing contractions into a single regex pattern string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(ain't|aren't|can't|can't've|'cause|could've|couldn't|couldn't've|didn't|doesn't|don't|hadn't|hadn't've|hasn't|haven't|he'd|he'd've|he'll|he'll've|he's|how'd|how'd'y|how'll|how's|I'd|I'd've|I'll|I'll've|I'm|I've|isn't|it'd|it'd've|it'll|it'll've|it's|let's|ma'am|mayn't|might've|mightn't|mightn't've|must've|mustn't|mustn't've|needn't|needn't've|o'clock|oughtn't|oughtn't've|shan't|sha'n't|shan't've|she'd|she'd've|she'll|she'll've|she's|should've|shouldn't|shouldn't've|so've|so's|that'd|that'd've|that's|there'd|there'd've|there's|they'd|they'd've|they'll|they'll've|they're|they've|to've|wasn't|we'd|we'd've|we'll|we'll've|we're|we've|weren't|what'll|what'll've|what're|what's|what've|when's|when've|where'd|where's|where've|who'll|who'll've|who's|who've|why's|why've|will've|won't|won't've|would've|wouldn't|wouldn't've|y'all|y'all'd|y'all'd've|y'all're|y'all've|you'd|you'd've|you'll|you'll've|you're|you've)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'(%s)' % '|'.join(ContractionsMap.keys())   # combine all dictionary keys containing contraction words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carefully walk-through the `unContract_specific()` function to understand what it does to keys and values of the dictionary `ContractionsMap`. The `re.compile()` precompiles a regex string to speed up the regex search  further. A helper function `ReplaceMatches()` is passed to the regex's `sub()` method. Whenever it finds a matching contraction, it returns the corresponding expansion for the matched string of [`re.Match`](https://docs.python.org/3/library/re.html#match-objects) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def unContract_specific(sTxt='', cmap=ContractionsMap) -> str:\n",
    "    '''Expand contractions in sTxt string with contraction patterns from cmap\n",
    "    Input:\n",
    "        sTxt: input string with contractions that need expansion\n",
    "    Return:\n",
    "        sTxt with expanded contractions    '''\n",
    "\n",
    "    # Search string of contractions: \"(ain't|aren't|can't|can't've|'cause|...)\"\n",
    "    reSearch = '(%s)' % '|'.join(ContractionsMap.keys())\n",
    "    cre = re.compile(reSearch)  # compile regex search for speed\n",
    "\n",
    "    def ReplaceMatches(match): \n",
    "    # retrieves matched expansion based on matched pattern group\n",
    "        return cmap[match.group(0)]\n",
    "\n",
    "    # substitute contraction matches with expansions:\n",
    "    return cre.sub(ReplaceMatches, sTxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the specific set of rules to the `sTxt` to confirm that it expands the correct contraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are welcome in Ed's kitchen\n"
     ]
    }
   ],
   "source": [
    "sTxt = \"you're welcome in Ed's kitchen\"\n",
    "print(unContract_specific(sTxt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`contractions`](https://pypi.org/project/contractions/) package conveniently wraps these rules and provides some flexibility to add new ones. Caution:\n",
    "* a contraction can use [apostrophe](https://en.wikipedia.org/wiki/Apostrophe), [single quote](https://en.wikipedia.org/wiki/Quotation_mark#Summary_table), backquote, [grave mark](https://en.wikipedia.org/wiki/Grave_accent#Use_in_programming) and other similar-looking symbols. Some preprocessing may be needed to standardize all these marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We are mining bitcoins on John's computer\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sTxt = \"We're mining bitcoins on John's computer\"\n",
    "contractions.fix(sTxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# Optional Practice\n",
    "\n",
    "You will practice fixing the contractions in `sAlice` and the following string. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sTxt = \"We're mining bitcoins on John's computer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you work through these tasks, check your answers by running your code in the *#check solution here* cell, to see if you've gotten the correct result. If you get stuck on a task, click the See **solution** drop-down menu to view the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Fix contractions in `sTxt` by applying the `fix()` function from the contractions library.\n",
    "\n",
    "<b>Hint:</b> This code is the same as the application of contractions package above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#B31B1B>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "contractions.fix(sTxt)\n",
    "            </pre>\n",
    "    </details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Use `nltk.word_tokenize()` to parse `sAlice` into a list of word tokens and save this as `LsAlice`. How many elements are in `sAlice`?\n",
    "\n",
    "<b>Hint:</b> It's a simple application of <code>nltk.word_tokenize()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#B31B1B>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "LsAlice = nltk.word_tokenize(sAlice)\n",
    "len(LsAlice)\n",
    "            </pre>\n",
    "    </details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Apply the `fix` method to `sAlice` to expand contractions, tokenize the string with `word_tokenize()`, and save the list of word tokens to `LsAliceCE`. How many elements are in this list? Since some words will be expanded into two or more words, you should be observing a larger count.\n",
    "\n",
    "<b>Hint:</b> It's a simple application of <code>nltk.word_tokenize()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#B31B1B>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "LsAliceCE = nltk.word_tokenize(contractions.fix(sAlice))\n",
    "len(LsAliceCE)\n",
    "            </pre>\n",
    "    </details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Apply `set()` to `LsAlice` list to remove duplicates and save this set of strings as `SsAlice`. What is the cardinality of this set (i.e., how many elements are in it)? \n",
    "\n",
    "<b>Hint:</b>  It's a simple application of <code>set()</code> to the list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#B31B1B>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "SsAlice = set(LsAlice)\n",
    "len(SsAlice)\n",
    "            </pre>\n",
    "    </details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Similarly, apply `set()` to `LsAliceCE` to remove duplicates and save this set of strings to `SsAliceCE`. What is the cardinality of this set? \n",
    "\n",
    "<b>Hint:</b> It's a simple application of <code>set()</code> to the list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#B31B1B>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "SsAliceCE = set(LsAliceCE)\n",
    "len(SsAliceCE)\n",
    "            </pre>\n",
    "    </details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Find all elements in `SsAliceCE` that are not in `SsAlice`. Your output should be word tokens that were not in the original text.\n",
    "\n",
    "<b>Hint:</b> Use <code>.difference()</code> method of a set object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#B31B1B>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "SsAliceCE.difference(SsAlice)\n",
    "SsAliceCE - SsAlice              # alternative notation for set difference\n",
    "            </pre>\n",
    "    </details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "\n",
    "Find all elements in `SsAlice` that are not in `SsAliceCE` and save them to `LsOdd`. This odd output contains word tokens that are not in the preprocessed text because they were expanded. You should find 41 word tokens in the expanded text. \n",
    "\n",
    "<b>Hint:</b> Just like you did above, find the set difference in this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#B31B1B>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "LsOdd = SsAlice.difference(SsAliceCE)\n",
    "print(LsOdd)\n",
    "len(LsOdd)\n",
    "            </pre>\n",
    "    </details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8\n",
    "\n",
    "Take a closer look at `LsOdd`. Some of these elements are legitimate contractions that need expansion, but others are incomplete word parts. Why are these not appearing in `SsAliceCE` after expansion? This is an semi-open ended analytical question that requires you to investigate the text closer with the tools you have learned so far.\n",
    "\n",
    "<b>Hint:</b> You can use <code>re.finditer</code> to find all match objects with starting and ending positions. Then you can offset these positions 10 characters wider and slice out a larger phrase containing the search pattern. Then tokenize this phrase with and without contraction expansion. You can place these operations in a loop for automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#B31B1B>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "sOddToken = \"'sha\"\n",
    "MO = re.finditer(sOddToken, sAlice) # match iterator\n",
    "sPhrases = [sAlice[max(0,mo.start()-10):min(len(sAlice), mo.end()+10)] for mo in MO]\n",
    "sPhrases\n",
    "print([nltk.word_tokenize(s) for s in sPhrases])\n",
    "print([nltk.word_tokenize(contractions.fix(s)) for s in sPhrases])\n",
    "            </pre>\n",
    "    </details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9\n",
    "\n",
    "Find all unique tokens in `SsAliceCE` that still contain a single quote. How many are there?\n",
    "\n",
    "<b>Hint:</b> Try a conditional set comprehension. In the condition check if <code>\"'\"</code> is in the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#B31B1B>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "SsContr = {s for s in SsAliceCE if \"'\" in s}\n",
    "len(SsContr)\n",
    "            </pre>\n",
    "    </details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10\n",
    "\n",
    "Find all tokens in `SsAliceCE` that still contain a single quote, but not as the first character of a token. Save this set of strings to `SsContrMid`. How many are there?\n",
    "\n",
    "<b>Hint:</b> Same as above, but also check if the first character (at zero's position) is alpha or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#B31B1B>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "SsContrMid = {s for s in SsAliceCE if s[0].isalpha() and \"'\" in s}\n",
    "len(SsContrMid)\n",
    "            </pre>\n",
    "    </details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11\n",
    "\n",
    "Count number of instances of each element of `SsContrMid` in `sAlice` text. Think about ways you might want to improve your preprocessing pipeline to expand these contractions too.\n",
    "\n",
    "<b>Hint:</b> Try <code>re.findall()</code> to find all instances of the search pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details>\n",
    "        <summary><font color=#B31B1B>▶</font>\n",
    "            See <b>solution</b>.\n",
    "        </summary>\n",
    "            <pre>\n",
    "[(len(re.findall(s, sAlice)), s) for s in SsContrMid]\n",
    "            </pre>\n",
    "    </details> \n",
    "</font>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
